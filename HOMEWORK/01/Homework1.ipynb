{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# HOMEWORK 1 / Data Manipulation, Pandas and Distance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__This assignment is worth up to 15 POINTS to your grade total if you do it and turn it in on time.  Late assignments will lose 15%.__\n",
    "\n",
    "\n",
    "| Points Possible | Due Date |\n",
    "|:---------------:|:--------:|\n",
    "| 15 | Wednesday, Sep. 28 @ Midnight|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBJECTIVE\n",
    "* Learn how to use Pandas for data ingest, manipulation and summarization.\n",
    "* Learn to perform a simple exploratory data analysis to plot data and visualize outcomes.\n",
    "* Understand how to use and interpret Pearson-_r_ for correlation.\n",
    "* Implement $k$-Nearest Neighbors and see a distance metric in action on real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WHAT TO TURN IN\n",
    "\n",
    "You are being encouraged to turn the assignment in using the provided Jupyter Notebook.  To do so, clone the repository and modify the `Homework1.ipynb` file in the `HOMEWORK/01` directory.\n",
    "\n",
    "Turn in a copy of a ipynb file OR a PDF or Word Document to Blackboard with the answers to the questions labeled with the &#167; sign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESOURCES\n",
    "\n",
    "### Datasets\n",
    "\n",
    "| Dataset | Summary | Size |\n",
    "|---------|---------|------|\n",
    "|[Salt Lake City Water Usage Jan-July 2016](http://www.civicdata.io/dataset/slc_water_usage_1/resource/a2bc8285-d9ef-45ca-ae86-bf735bc5011a) | Real data that includes water usage for various property types, connection counts, etc. | > 40K instances, < 10 features |\n",
    "|[Sacramento Real Estate transactions, May 15-21, 2008](http://samplecsvs.s3.amazonaws.com/Sacramentorealestatetransactions.csv).  Also found [archived here in the repo](./Sacramentorealestatetransactions.csv).| Sacramento transcation data from real estate properties sold in a single week in 2008.  Includes latitude, longitude, prices, addresses, and basic property characteristics (# beds, square footage, etc.) | > 900 instances, < 10 features |\n",
    "\n",
    "### Pandas\n",
    "\n",
    "http://pandas.pydata.org/\n",
    "\n",
    "### Jupyter Notebooks\n",
    "\n",
    "http://jupyter.org\n",
    "\n",
    "### Code \n",
    "\n",
    "You might need to use the following at the beginning of your Jupyter notebook:\n",
    "```python\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOW TO COMPLETE THIS ASSIGNMENT / ASSIGNMENT DETAILS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1 / Python Pandas\n",
    "\n",
    "For this part you will need to load and analyze data using [Pandas](http://pandas.pydata.org). \n",
    "\n",
    "Familiarize yourself with the dataset from the [spatialkey.com](https://support.spatialkey.com/spatialkey-sample-csv-data/) website.  In particular, we will be working with the dataset here:\n",
    "![sacramento dataset](./spatialkey_screenshot01.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###  &#167; Write the Python code to load the [CSV file from spatialkey](http://samplecsvs.s3.amazonaws.com/Sacramentorealestatetransactions.csv) directly into a Pandas dataframe.  \n",
    " * You may need to familiarize yourself with the [IO Tools](http://pandas.pydata.org/pandas-docs/stable/io.html) functions of Pandas.\n",
    " * Load the file to your local file system where the running code exists (e.g. the CSV file should exist in the same location as your code or notebook).\n",
    " * Turn in the fragment of code that does this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my answer\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print \"my answer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#167;  Compute the price per square foot for all properties.  Add this data back into the dataframe.  \n",
    " * See the documentation on [concatening objects](http://pandas.pydata.org/pandas-docs/stable/merging.html#concatenating-objects).\n",
    " * Turn in the code that does this, and show the results of `head()` and `tail()` on the new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39215686274509803"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ppsf(some_number, another_number):\n",
    "    return some_number / (another_number * 1.7)\n",
    "\n",
    "ppsf(20, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#167;  Provide three data points from the original dataset that give you reason to be concerned about the some of the properties with unusual price per square foot data.\n",
    " * Learn about [summarizing your data](http://pandas.pydata.org/pandas-docs/stable/basics.html#descriptive-statistics) and [sorting](http://pandas.pydata.org/pandas-docs/stable/basics.html#by-values).\n",
    " * Turn in the rows of those three data points and 1 to 3 sentences discussing your concerns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#167;  Use a scatter plot to plot the sale price to the square feet.  \n",
    "\n",
    "### &#167;  Do the same for number of beds to sale price.\n",
    "* You will need to learn about [scatter plots](http://pandas.pydata.org/pandas-docs/stable/basics.html#descriptive-statistics) to complete these.\n",
    "* For both, turn in the scatter plot &#emdash; if you're using Jupyter, just leave the plots inline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#167; Explore the distribution of properties by number of beds.  Plot this using `plot()` \n",
    "* Learn about that function [here](http://pandas.pydata.org/pandas-docs/stable/visualization.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2 / Distance metrics and _k_-Nearest Neighbor\n",
    "\n",
    "### &#167; Implement the _k_-Nearest Neighbor algorithm in Python using the Euclidean distance metric.\n",
    "\n",
    "The _k_-Nearest Neighbor algorithm is a very simple _lazy learning_ algorithm.  It computes $k$ neigbors given a data point $d_i$ (vector) from the set of all data $D = \\{d_1, d_2, \\ldots, d_i, \\ldots, d_n\\}$.\n",
    "\n",
    "\n",
    "#### 1. Implement the function `d_euclidean(v1, v2)` that takes 2 arguments v1 and v2 which are the vectors you will be comparing from your dataset.\n",
    "\n",
    "You will be turning in the implementation of two functions.  The first is the Euclidean distance function, which is trivial to implement.  Recall Euclidean distance $d_{\\mathrm{euclidean}}$ is defined by, given two vectors $v_1$ and $v_2$ of length $n$ :\n",
    "\n",
    "$$\n",
    "d_{\\mathrm{euclidean}} = \\sqrt{ {\\sum_{i=1}^n \\big({v_1}_i - {v_2}_i\\big)}^2 }\n",
    "$$\n",
    "\n",
    "You are free to use the implementation in the notes, but please make sure you actually cite it appropriately if you copy it verbatim!\n",
    "\n",
    "#### 2. Implement the function `knn_euclidean(k, v, d)`that takes two arguments, the number of neighbors to return _k_ the data vector _v_ and the entire dataset _d_.\n",
    "\n",
    "The algorithm will do the following:\n",
    "1. compute the distance between $v$ and all vectors in $d$ (with $v$ removed, if you like, but the distance between $v$ and itself will be ... 0!).  You will use the function from part 1 `d_euclidean`.\n",
    "2. sort the distances of all vectors in descending order with the closest (lowest) distances first.\n",
    "3. return the _k_ top neighbors\n",
    "\n",
    "Your Python code might look something like this:\n",
    "\n",
    "#### What you will turn in:\n",
    "\n",
    "* Turn in the code for the two functions implemented in Python.\n",
    "* Use the templates below :\n",
    "\n",
    "```python\n",
    "\n",
    "# assume v1 and v2 are python tuples\n",
    "def d_euclidean(v1, v2):\n",
    "    return # the calculation of the euclidean distance\n",
    "\n",
    "\n",
    "# implement the knn algorithm as defined above\n",
    "def knn_euclidean(k, v, all_v):\n",
    "\n",
    "    # compute all the distances between v and d_v in all_v\n",
    "    for d_v in all_v:\n",
    "        d_euclidean(d_v, v)\n",
    "\n",
    "    # store the distances, sort and return k of them\n",
    "    \n",
    "    # the rest of your implementation\n",
    "    \n",
    "    return # the top k vectors sorted\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#167; Produce the distance table using your version of _k_-NN for all properties.  \n",
    "\n",
    "*  To make things easier, please reduce the data vector to just beds, bath, square footage, price, latitude and longitude.\n",
    "* You can use the street as the index.  Your final output will look something like this:\n",
    "\n",
    "\n",
    "<div class=\"tg-wrap\"><table>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td>3526 HIGH ST</td>\n",
    "    <td>51 OMAHA CT</td>\n",
    "    <td>C2796 BRANCH ST</td>\n",
    "    <td>D2805 JANETTE WAY</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3526 HIGH ST</td>\n",
    "    <td>0</td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>51 OMAHA CT</td>\n",
    "    <td>0.25<br></td>\n",
    "    <td>0</td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2796 BRANCH ST</td>\n",
    "    <td>0.25</td>\n",
    "    <td>0.25</td>\n",
    "    <td>0</td>\n",
    "    <td></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2805 JANETTE WAY</td>\n",
    "    <td>0.25</td>\n",
    "    <td>0.25</td>\n",
    "    <td>0.25</td>\n",
    "    <td>0</td>\n",
    "  </tr>\n",
    "</table></div>\n",
    "\n",
    "\n",
    "### &#167; Compute the 4-NN and 5-NN to the following properties:\n",
    "\n",
    "- 4882 BANDALIN WAY\n",
    "- 7511 OAKVALE CT\n",
    "* 7731 MASTERS ST\n",
    "* 4925 PERCHERON DR\n",
    "* 4727 SAVOIE WAY\n",
    "* 3228 BAGGAN CT\n",
    "* 8515 DARTFORD DR\n",
    "* 2460 EL ROCCO WAY\n",
    "* 5840 WALERGA RD\n",
    "* 923 FULTON AVE\n",
    "* 4030 BROADWAY\n",
    "* 6485 LAGUNA MIRAGE LN\n",
    "* 8758 LEMAS RD\n",
    "* 1140 EDMONTON DR\n",
    "* 1890 GENEVA PL\n",
    "\n",
    "Turn in the table that has each property address and the addresses of the 4-NN and 5-NN properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## PART 3 / Data Exploration\n",
    "\n",
    "For this part we will be using the data from the [Salt Lake City water usage dataset (by block)](http://www.civicdata.io/dataset/slc_water_usage_1/resource/a2bc8285-d9ef-45ca-ae86-bf735bc5011a).  This dataset includes information about water consumption for 2016.\n",
    "\n",
    "## Explore the data:\n",
    "\n",
    "### &#167; How many different property types are described in this data?\n",
    "### &#167; How many much of consumption data is less than 0?\n",
    "### &#167; Produce a histogram of the monthly consumption for all property types?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix the data\n",
    "There are some data in the input that needs work. In particular, the property descriptions have issues.  Fix them (**hint:** explore [strip()]() and [lower()]()).  Also please remove all data points that are out of spec, that is connections less than 0 and consumption less than 0.\n",
    "\n",
    "### &#167; How many data points do you now have?\n",
    "### &#167; Show the descriptive stats for this new fixed data: For consumption and connections only, what is the mean, media, min and max?\n",
    "### &#167; Normalize the data using z-score normalization for connection and consumption.  Show the `head()` and `tail()` of the new values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore relationships\n",
    "\n",
    "### &#167; Plot the connections (x-axis) to consumption (y-axis) in scatter plot.  Is there a relationship?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#167; Compute the Pearson's _r_ correlation between these two?  Does it confirm what you see?\n",
    "* You will need to investigate the [scipy Pearson's _r_ for this part](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### &#167; Group the data by month and by property type and show the bar plot of this for the year-to-date day (January to July).\n",
    "\n",
    "* You will need to read up on the [groupby]() function in Pandas for the next few questions. \n",
    "* Also read up on plotting/visualizing in Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS\n",
    "\n",
    "## This analysis optional, but you will receive 1 bonus point for each question you answer below.\n",
    "\n",
    "### _Water consumption rises dramatically in June and July -- let's explore why?_\n",
    "### &#167; Analyze the data for May, June and July and produce a bar plot of the consumpution over those three months.\n",
    "### &#167; Explain what you see.  Of course, during the summer months, the temperatures are higher and thus water consumption would naturally go up, but given what you see in the plot, what else is going on?\n",
    "\n",
    "* _Hints_: You will need to understand how to use [aggregate()](http://pandas.pydata.org/pandas-docs/stable/groupby.html#aggregation) and maybe [get_level_values()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.CategoricalIndex.get_level_values.html#pandas.CategoricalIndex.get_level_values).  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
