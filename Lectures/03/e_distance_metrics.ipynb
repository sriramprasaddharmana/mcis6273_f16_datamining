{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance and Similarity Metrics\n",
    "\n",
    "With distance and similarity measures we want to know how close two data points are.  This is not unlike your Geometry courses where you want to find out if two points in 2-D or 3-D space.  Once you got to Calculus and Linear Algrebra, you learned that these ideas can extend into $n$-space.\n",
    "\n",
    "Going back to our discussion of vectors of our data, we are first going to look at only a few common distance metrics, then we will extend the discussion to similarity metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Distance\n",
    "\n",
    "Simple and straightforward distance metric that computes the distance and sums the squares of those distances. It can performs well when the data is scaled.\n",
    "\n",
    "$$ d(\\mathbf{x},\\mathbf{y}) = \\sqrt { \\sum_{i=1}^{n} \\big( x_i - y_i \\big)^2 } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def d_euclidean(x, y, p=2):\n",
    "    if len(x) != len(y):\n",
    "        raise Exception\n",
    "    else:\n",
    "        v_sum = 0\n",
    "        for x_i, y_i in zip(x, y):\n",
    "            v_sum = v_sum + (x_i-y_i)**p\n",
    "        return v_sum**(1/p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manhattan Distance\n",
    "\n",
    "Manhattan distance is another popular distance metric that considers the rectilinear \"taxi cab\" distance between two points.  Consider street blocks where all points are formed at right angles to one another -- the Manhattan distance of two points is equal to sum of length the horizontal and vertical distances (contrast with the diagonal or \"crows flies\" distance\".\n",
    "\n",
    "This distance is given by:\n",
    "\n",
    "$$ d(\\mathbf{x},\\mathbf{y}) = \\sum_{i=1}^N \\big| x_i - y_i \\big| $$\n",
    "\n",
    "\n",
    "The blue, read and yellow paths in the diagram below are all equivalent  Manhattan distances:\n",
    "\n",
    "<img src=\"./Manhattan_distance.svg\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minkoski Distance\n",
    "A generalized distance metric where generally $1 \\lt p \\le 2$.  Notice that when $p=2$ Minkoski is the Euclidean distance, and when $p=1$ it is the Manhattan distance.\n",
    "\n",
    "$$ d(\\mathbf{x},\\mathbf{y}) =\n",
    "\\big(\n",
    "\\sum_{i=1}^n { \\big| x_i - y_i \\big| }^p\n",
    "\\big)^{1/p}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity\n",
    "\n",
    "With similarity metrics we want to know how similar two data vectors are.  We will use similarity and distance to determine whether two data points share features in common and should thus be considered in clustering, classification, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "\n",
    "A measure of similarity between two vectors that computes the cosine of the angle between them such that the result is between -1 and 1. The similarity is thus given by, \n",
    "\n",
    "$$ d(\\mathbf{x}, \\mathbf{y}) = { \n",
    "{ \\sum_{i=1}^n {x_i y_i} } \\over \n",
    "{ \\sqrt {\\sum_{i=1}^n x_i^2}} { \\sqrt {\\sum_{i=1}^n y_i^2 }}\n",
    "}$$\n",
    "\n",
    "If $d(\\mathbf{x}, \\mathbf{y})$ is 0 then $\\mathbf{x}$ and $\\mathbf{y}$ are orthogonal or not correlated.  If 1, then two vectors are the same and if -1, completely opposite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sim_cosine(x,y):\n",
    "    sum_xy, sum_xx, sum_yy = 0, 0, 0\n",
    "    \n",
    "    if len(x) != len(y):\n",
    "        raise Exception\n",
    "    else:\n",
    "        for x_i, y_i in zip(x,y):\n",
    "            sum_xy = sum_xy + (x_i*y_i)\n",
    "            sum_xx = sum_xx + (x_i*x_i)\n",
    "            sum_yy = sum_yy + (y_i*y_i)\n",
    "        return 1.0*sum_xy / ((sum_xx**.5)*(sum_yy**.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahalanobis distance\n",
    "The Mahalanobis distance is a unitless, scale-invariant distance metric that takes into account the number of standard deviations a vector is from the mean of the dataset $D$. Note, if data is rescaled to have unit variance, then Mahalanobis distance is equivalent to Euclidean distance. Mahalanobis accounts for correlations in a data set and can be valuable in detecting outliers.  This measurement can be used as a similarity metric when comparing two data vectors $\\mathbf{x}$ and $\\mathbf{y}$.\n",
    "\n",
    "$$ d(\\mathbf{x}, \\mathbf{y}) =  \\sqrt { (\\mathbf{x}-\\mathbf{y})^{T} S^{-1} (\\mathbf{x}-\\mathbf{y}) }\n",
    "$$\n",
    "\n",
    "with $S$ the covariance matrix.  We will re-visit this metric and explore the details of the implementation.\n",
    "\n",
    "<!-- todo: explanation of S covariance matrix. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hamming distance\n",
    "\n",
    "The Hamming distance provides a metric that sums the positional differences between two vectors of the same length.  For example, consider two numeric vectors $v_1 = (1,2,3,5)$ and $v_2 = (1,3,3,5)$.  The Hamming distance between these two vectors is 1 since the number of positions that differ between them is $v_{12} \\ne v_{22}$. Hamming distance is often used to compare the similarity between words.  Consider two words, \"firth\" and \"froth\", the Hamming distance is 2.  Whereas the Hamming distance between \"forth\" and \"great\" is 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adapted from Python 3 implementation at https://en.wikipedia.org/wiki/Hamming_distance\n",
    "def d_hamming(x, y):\n",
    "    if len(x) != len(y):\n",
    "        raise Error\n",
    "    return sum(x_i != y_i for x_i, y_i in zip(x, y))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}